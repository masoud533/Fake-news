{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "056189a5-b39d-4e02-8355-e177baf1ca00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a441e896-76d4-4519-aa89-2e6c263381de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to database\n",
    "path = os.path.join('..', 'Database', 'news.db')\n",
    "conn = sqlite3.connect(path)\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a4802b3-d5f5-491c-ba3e-14c189d48237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Load TF-IDF features\n",
    "cursor.execute(\"SELECT data FROM features WHERE type = 'tfidf'\")\n",
    "X_tfidf_compressed = cursor.fetchone()[0]\n",
    "X_tfidf = pickle.loads(X_tfidf_compressed)\n",
    "print(\"Features loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b289f70a-799f-452a-be6c-6009dd0db596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load labels from the original dataset\n",
    "df= pd.read_sql(\"SELECT id, label FROM cleanedText\", conn) \n",
    "df['label'] = df['label'].apply(lambda x: 1 if x == 'real' else (0 if x == 'fake' else None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b094c7e-653a-4c17-a195-7180d2c84aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming X_tfidf is the extracted features\n",
    "y = df['label'].values # Labels (0: Fake, 1: Real) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2039e50a-92a4-4c20-a3a6-fe6c722575aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data split into training and testing sets!\n",
      "Train size:  (35918, 5000) Test size:  (8980, 5000)\n"
     ]
    }
   ],
   "source": [
    "# Split data into 80% training and 20% testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=1311)\n",
    "print(\"Data split into training and testing sets!\")\n",
    "print(\"Train size: \", X_train.shape, \"Test size: \", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e0c2ae5-575e-4cc9-b2f9-77627d2c7fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a wide range of C values for regularization strength\n",
    "C_values = np.logspace(-4, 4, 10) # 10 values from 0.0001 to 10,000\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    \"C\": C_values,\n",
    "    \"penalty\": [\"l1\", \"l2\"],  # Test both L1 and L2 regularization\n",
    "    \"solver\": [\"liblinear\", \"saga\"]  # Suitable solvers for L1 and L2\n",
    "}\n",
    "\n",
    "# Initialize Grid Search with 10-Fold Cross Validation\n",
    "grid_search = GridSearchCV(\n",
    "    LogisticRegression(max_iter=5000),  # Increase max_iter to ensure convergence\n",
    "    param_grid,\n",
    "    cv=10,  # 10-Fold Cross Validation\n",
    "    scoring=\"accuracy\",\n",
    "    n_jobs=-1,  # Use all CPU cores for faster execution\n",
    "    verbose=5  # Display detailed progress\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d62294-7be4-4e44-9c5c-37d4c9efea13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 40 candidates, totalling 400 fits\n"
     ]
    }
   ],
   "source": [
    "# Fit the model on the training data\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de3720f-afa8-420a-8c53-aec2b43764d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the best hyperparameters and the corresponding accuracy\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Cross-Validation Accuracy:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96b7ca9-2bc9-45bb-87d3-f86af4696110",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58c209d-c005-4bc1-99e6-30802437b589",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
